\section{Preliminaries}
The goal of sparse coding is to represent input vectors $\mathbf{y}$ approximately as a linear combination of a small number of basis vectors $\{\mathbf{x}_i\}_{i=1}^n$.
More precisely, any given input vector $\mathbf{y}\in R^k$ is compactly represented using basis vectors $\mathbf{x}_1,\,\mathbf{x}_2,\cdots,\,\mathbf{x}_n\in R^k$ and a sparse vector of coefficients $\mathbf{a}=(a_1,\,a_2,\cdots ,\,a_n)^T\in R^n$ such that $\mathbf{y} \approx \sum_i a_i\mathbf{x}_i$.
Here the basis vectors can be overcomplete ($n>k$) and thus sparse coding can capture high-level patterns in the input.

To make this paper self contained, here we introduce some basic notations.
Let $\mathbf{x}=(x_1,\,x_2,\,\cdots ,\,x_k)^T$ be any vector in Euclidean space $R^k$, $\|\mathbf{x}\|_p$  is the $\ell_p$ norm of $\mathbf{x}$ with $\|\mathbf{x}\|_p=(\sum_{i=1}^k |x_i|^p)^{1/p}$. And the $\ell_0$ pseudo-norm of $\mathbf{x}$ is defined as $\|\mathbf{x}_0\|=\#\{i|x_i\neq 0\}=\sum_{i=1}^k |x_i|^0$.
$\mathbf{X}=(x_{ij})$ is denoted as a matrix in space $R^{m\times n}$.
Frobenius norm of $\mathbf{X}$ is given by $\|\mathbf{X}\|_F=(\sum_{i=1}^m\sum_{i=1}^n x_{ij}^2)^{1/2}$.
%These vectors thus capture high-level patterns in the input data or vector.
