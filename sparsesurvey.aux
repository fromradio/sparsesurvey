\relax 
\bibstyle{elsarticle-num}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction\relax }{section.1}{}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{1}{section.2}}
\newlabel{sec:preliminaries}{{2}{1}{Preliminaries\relax }{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The Problems of Sparse Coding}{1}{section.3}}
\newlabel{sec:problem of SR}{{3}{1}{The Problems of Sparse Coding\relax }{section.3}{}}
\citation{mallat1993matching}
\citation{pati1993orthogonal,tropp2007signal}
\citation{pati1993orthogonal}
\citation{tibshirani1996regression}
\citation{efron2004least}
\citation{wright2010sparse}
\citation{wright2009robust}
\citation{yang2008image}
\citation{mairal2008discriminative}
\citation{olshausen1997sparse,engan1999frame}
\citation{aharon2006svd}
\citation{aharon2006svd}
\citation{jolliffe2005principal,wold1987principal}
\citation{wright2009robust,candes2011robust}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sparse Coding}{2}{subsection.3.1}}
\newlabel{subsec:sparse coding}{{3.1}{2}{Sparse Coding\relax }{subsection.3.1}{}}
\newlabel{eq-sparse}{{1}{2}{Sparse Coding\relax }{equation.3.1}{}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Dictionary Learning.}{2}{subsection.3.2}}
\newlabel{eq-diclearning}{{6}{2}{Dictionary Learning}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Compressed Sensing}{2}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Low rank representation and robust principle component analysis}{2}{subsection.3.4}}
\newlabel{eq-lowrank}{{7}{2}{Low rank representation and robust principle component analysis\relax }{equation.3.7}{}}
\citation{candes2009exact,wright2009robust}
\citation{lin2010augmented}
\citation{grant2008cvx}
\citation{wright2009robust}
\citation{beck2009fast}
\citation{lin2009fast}
\citation{lin2010augmented}
\citation{bertsekas1982constrained}
\citation{bertsekas1999nonlinear}
\citation{lin2010augmented}
\citation{ma2012sparse}
\citation{shen2012unified}
\citation{ji2010robust}
\citation{lipman2007parameterization}
\citation{huang2009consolidation}
\citation{preiner2014CPF}
\citation{avron2010L1}
\citation{mustafa2014subdivision}
\citation{zhang2013point}
\citation{he2013mesh}
\citation{wang2014decoupling}
\citation{zhang2014variational}
\citation{bouaziz2013sparse}
\citation{zhang2014variational}
\citation{hu2012co}
\citation{digne2014self}
\citation{miandji2013learning}
\citation{zhang2012variational}
\citation{neumann2013sparse}
\citation{le2012smooth}
\citation{le2013two}
\citation{le2014ras}
\citation{deng2013exploring}
\citation{jin2012unsupervised}
\citation{wang2014upright}
\citation{neumann2014compressed}
\citation{zhang2014local}
\citation{huang2013l1}
\citation{xiong2014robust}
\citation{brown1983statistical,small1990survey}
\@LN@col{1}
\newlabel{eq-lowranksparse}{{8}{3}{Low rank representation and robust principle component analysis\relax }{equation.3.8}{}}
\newlabel{eq-lowrankorigin}{{9}{3}{Low rank representation and robust principle component analysis\relax }{equation.3.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Numerical solution}{3}{section*.1}}
\newlabel{eq-generalalm}{{10}{3}{Numerical solution\relax }{equation.3.10}{}}
\newlabel{eq-lowrankalm}{{12}{3}{Numerical solution\relax }{equation.3.12}{}}
\@LN@col{2}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of applications between image and geometry.}}{3}{table.1}}
\newlabel{table:difference}{{1}{3}{Comparison of applications between image and geometry}{table.1}{}}
\newlabel{sec:Survey}{{3.4}{3}{Numerical solution\relax }{equation.3.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Sparse Regularization}{3}{section.4}}
\newlabel{sec:Sparse Regularization}{{4}{3}{Sparse Regularization\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Point Cloud Consolidation}{3}{subsection.4.1}}
\newlabel{subsec:Point Cloud Consolidation}{{4.1}{3}{Point Cloud Consolidation\relax }{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}$\ell _1$ median based}{3}{subsubsection.4.1.1}}
\newlabel{subsubsec:l1 median based}{{4.1.1}{3}{$\ell _1$ median based\relax }{subsubsection.4.1.1}{}}
\citation{lipman2007parameterization}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces An overview about the effectiveness of sparsity in all the papers.}}{4}{table.2}}
\newlabel{table:overview}{{2}{4}{An overview about the effectiveness of sparsity in all the papers}{table.2}{}}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Reconstruction by projection operation. (a). noisy point-set P(green) and an arbitrary point-set Q(red) that will be projected to P to approximate P. (b),(c) are two iterative projection results. (d) is the final projection.}}{4}{figure.1}}
\newlabel{fig:L1 median}{{1}{4}{Reconstruction by projection operation. (a). noisy point-set P(green) and an arbitrary point-set Q(red) that will be projected to P to approximate P. (b),(c) are two iterative projection results. (d) is the final projection}{figure.1}{}}
\newlabel{eq:L1median}{{13}{4}{$\ell _1$ median based\relax }{equation.4.13}{}}
\@writefile{toc}{\contentsline {paragraph}{(1)}{4}{section*.2}}
\@LN@col{2}
\newlabel{eq:LOP1}{{14}{4}{(1)\relax }{equation.4.14}{}}
\newlabel{eq:LOP2}{{15}{4}{(1)\relax }{equation.4.15}{}}
\citation{lipman2007parameterization}
\citation{huang2009consolidation}
\citation{preiner2014CPF}
\citation{lipman2007parameterization}
\citation{huang2009consolidation}
\citation{preiner2014CPF}
\citation{lipman2007parameterization}
\citation{huang2009consolidation}
\citation{preiner2014CPF}
\citation{mustafa2014subdivision}
\@LN@col{1}
\newlabel{eq:LOP3}{{16}{5}{(1)\relax }{equation.4.16}{}}
\newlabel{eq:LOP4}{{17}{5}{(1)\relax }{equation.4.17}{}}
\@writefile{toc}{\contentsline {paragraph}{(2)}{5}{section*.3}}
\newlabel{eq:WLOP}{{18}{5}{(2)\relax }{equation.4.18}{}}
\@LN@col{2}
\@writefile{toc}{\contentsline {paragraph}{(3)}{5}{section*.4}}
\newlabel{eq:CLOP1}{{19}{5}{(3)\relax }{equation.4.19}{}}
\newlabel{eq:CLOP2}{{20}{5}{(3)\relax }{equation.4.20}{}}
\newlabel{eq:CLOP3}{{21}{5}{(3)\relax }{equation.4.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Sparse regularization: point cloud consolidation. (a): LOP\cite  {lipman2007parameterization}. (b): WOLP\cite  {huang2009consolidation}. (c): continuous WLOP\cite  {preiner2014CPF}.}}{5}{figure.2}}
\newlabel{fig:L1 median consolidation}{{2}{5}{Sparse regularization: point cloud consolidation. (a): LOP\cite {lipman2007parameterization}. (b): WOLP\cite {huang2009consolidation}. (c): continuous WLOP\cite {preiner2014CPF}}{figure.2}{}}
\citation{mustafa2014subdivision}
\citation{mustafa2014subdivision}
\citation{xu2011image}
\citation{pinkall1993computing}
\citation{he2013mesh}
\citation{he2013mesh}
\citation{he2013mesh}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}$\ell _1$ regression based}{6}{subsubsection.4.1.2}}
\newlabel{eq:subdivision}{{22}{6}{$\ell _1$ regression based\relax }{equation.4.22}{}}
\newlabel{eq:subdivision regularization}{{23}{6}{$\ell _1$ regression based\relax }{equation.4.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Sparse regularization: $\ell _1$ based subdivision\cite  {mustafa2014subdivision}. Parametric surface reconstructed by $\ell _1$ scheme from highly noisy parametric data with outliers.}}{6}{figure.3}}
\newlabel{fig:subdivision}{{3}{6}{Sparse regularization: $\ell _1$ based subdivision\cite {mustafa2014subdivision}. Parametric surface reconstructed by $\ell _1$ scheme from highly noisy parametric data with outliers}{figure.3}{}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Mesh Denoising}{6}{subsection.4.2}}
\newlabel{subsec:L0 denoising}{{4.2}{6}{Mesh Denoising\relax }{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{(1)}{6}{section*.5}}
\newlabel{eq:imagesmooth}{{24}{6}{(1)\relax }{equation.4.24}{}}
\newlabel{fig:failureLaplaciandenoise}{{4.2}{6}{(1)\relax }{equation.4.24}{}}
\newlabel{fig:edgeoperator}{{4.2}{6}{(1)\relax }{equation.4.24}{}}
\newlabel{eq:edgecotanoperator}{{25}{6}{(1)\relax }{equation.4.25}{}}
\newlabel{eq:L0 denoise}{{26}{6}{(1)\relax }{equation.4.26}{}}
\citation{wang2014decoupling}
\citation{wang2014decoupling}
\citation{wang2014decoupling}
\citation{bouaziz2013sparse}
\citation{chartrand2007exact}
\citation{elad2010sparse}
\citation{chartrand2007exact}
\citation{chartrand2007exact}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sparse regularization: mesh denoising\cite  {he2013mesh}. Left: initial surface. Center: surface corrupted by Gaussian noise in random directions with standard deviation $\sigma =0.4l_{e}$($l_{e}$ is the mean edge length). Right: denoising result. The wireframe shows folded triangles as red edges.}}{7}{figure.4}}
\newlabel{fig:L0 denoise}{{4}{7}{Sparse regularization: mesh denoising\cite {he2013mesh}. Left: initial surface. Center: surface corrupted by Gaussian noise in random directions with standard deviation $\sigma =0.4l_{e}$($l_{e}$ is the mean edge length). Right: denoising result. The wireframe shows folded triangles as red edges}{figure.4}{}}
\@writefile{toc}{\contentsline {paragraph}{(2)}{7}{section*.6}}
\newlabel{eq:decoupling}{{27}{7}{(2)\relax }{equation.4.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Shape Matching}{7}{subsection.4.3}}
\newlabel{subsec:Shape Matching}{{4.3}{7}{Shape Matching\relax }{subsection.4.3}{}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Rigid registration}{7}{subsubsection.4.3.1}}
\newlabel{subsubsec:Rigid registration}{{4.3.1}{7}{Rigid registration\relax }{subsubsection.4.3.1}{}}
\newlabel{eq:ICP}{{28}{7}{Rigid registration\relax }{equation.4.28}{}}
\newlabel{eq:permutedsparse}{{29}{7}{Rigid registration\relax }{equation.4.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sparse regularization: rigid registration results using sparse ICP\cite  {chartrand2007exact} under different $l_{p}$ norms.}}{7}{figure.6}}
\newlabel{fig:sparseICP}{{6}{7}{Sparse regularization: rigid registration results using sparse ICP\cite {chartrand2007exact} under different $l_{p}$ norms}{figure.6}{}}
\citation{zhang2014local}
\citation{neumann2014compressed}
\citation{zhang2013point}
\citation{zhang2013point}
\citation{ovsjanikov2012functional}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sparse regularization: mesh denoising\cite  {wang2014decoupling}. (a) is the two-dimensional illustration for their key observation. (b) is a denoising example.}}{8}{figure.5}}
\newlabel{fig:decoupling}{{5}{8}{Sparse regularization: mesh denoising\cite {wang2014decoupling}. (a) is the two-dimensional illustration for their key observation. (b) is a denoising example}{figure.5}{}}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Non-rigid shape matching}{8}{subsubsection.4.3.2}}
\newlabel{subsubsec:non-rigid shape matching}{{4.3.2}{8}{Non-rigid shape matching\relax }{subsubsection.4.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{(1)Local functional basis}{8}{section*.7}}
\newlabel{eq:MHB}{{30}{8}{(1)Local functional basis\relax }{equation.4.30}{}}
\newlabel{eq:CMBA}{{31}{8}{(1)Local functional basis\relax }{equation.4.31}{}}
\@LN@col{2}
\newlabel{eq:discreteCMBA}{{32}{8}{(1)Local functional basis\relax }{equation.4.32}{}}
\@writefile{toc}{\contentsline {paragraph}{(2)Non-rigid shape matching}{8}{section*.8}}
\citation{pokrass2013sparse}
\citation{litman2011diffusion}
\citation{pokrass2013sparse}
\citation{wang2014decoupling}
\citation{wang2014decoupling}
\citation{hu2012co}
\citation{hu2012co}
\citation{hu2012co}
\citation{elhamifar2009sparse,wang2011efficient}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sparse regularization: local functional basis\cite  {zhang2013point}. The proposed compressed manifold modes(CMMs) have local support and are confined to specific local features like protrusions and ridges. 8 of the CMMs were found for the 8 protrusion at the corner(2 shown here), 6 concentrate at each of the dents(2 shown here), and 12 CMMs automatically form at the valleys between the protrusions.}}{9}{figure.7}}
\newlabel{fig:CMB}{{7}{9}{Sparse regularization: local functional basis\cite {zhang2013point}. The proposed compressed manifold modes(CMMs) have local support and are confined to specific local features like protrusions and ridges. 8 of the CMMs were found for the 8 protrusion at the corner(2 shown here), 6 concentrate at each of the dents(2 shown here), and 12 CMMs automatically form at the valleys between the protrusions}{figure.7}{}}
\newlabel{fig:regionmatching}{{4.3.2}{9}{(2)Non-rigid shape matching\relax }{section*.8}{}}
\newlabel{eq:non-rigid shape matching}{{33}{9}{(2)Non-rigid shape matching\relax }{equation.4.33}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sparse regularization: non-rigid shape matching \cite  {wang2014decoupling}. First row: point-to-point correspondences between different non-isometric shapes. Second row: point-to-point correspondence between SHREC shapes undergoing nearly isometric deformations and noise.}}{9}{figure.8}}
\newlabel{fig:non-rigid matching}{{8}{9}{Sparse regularization: non-rigid shape matching \cite {wang2014decoupling}. First row: point-to-point correspondences between different non-isometric shapes. Second row: point-to-point correspondence between SHREC shapes undergoing nearly isometric deformations and noise}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Co-segmentation}{9}{subsubsection.4.3.3}}
\newlabel{subsubsec:co-segmentation}{{4.3.3}{9}{Co-segmentation\relax }{subsubsection.4.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Sparse regularization: co-segmentation\cite  {hu2012co}. Colormaps of AGD features of two tables with over-segmented patches. The AGD feature vectors of the two patches(marked in rectangles) from each table's leg have similar distribution, as shown in histograms in the middle. It can be seen that these two feature vectors lie in the common subspace generated by standard basis corresponding to the nonzero entries.}}{9}{figure.9}}
\newlabel{fig:co-segmentationAGD}{{9}{9}{Sparse regularization: co-segmentation\cite {hu2012co}. Colormaps of AGD features of two tables with over-segmented patches. The AGD feature vectors of the two patches(marked in rectangles) from each table's leg have similar distribution, as shown in histograms in the middle. It can be seen that these two feature vectors lie in the common subspace generated by standard basis corresponding to the nonzero entries}{figure.9}{}}
\citation{shi2000normalized}
\citation{hu2012co}
\citation{hu2012co}
\citation{hu2012co}
\citation{huang2013l1}
\citation{cornea2007curve}
\citation{huang2009consolidation}
\citation{huang2013l1}
\citation{huang2013l1}
\citation{deng2013exploring}
\@LN@col{1}
\newlabel{eq:SSC}{{34}{10}{Co-segmentation\relax }{equation.4.34}{}}
\newlabel{eq:coseg1}{{35}{10}{Co-segmentation\relax }{equation.4.35}{}}
\newlabel{eq:coseg2}{{36}{10}{Co-segmentation\relax }{equation.4.36}{}}
\newlabel{eq:coseg3}{{37}{10}{Co-segmentation\relax }{equation.4.37}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Sparse regularization: co-segmentation\cite  {hu2012co}. Left shows the over segmented patches that will be clustered to get the co-segmentation result.}}{10}{figure.10}}
\newlabel{fig:co-segmentation}{{10}{10}{Sparse regularization: co-segmentation\cite {hu2012co}. Left shows the over segmented patches that will be clustered to get the co-segmentation result}{figure.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Skeleton Extraction}{10}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Deformation-Constrained Modeling}{10}{subsection.4.5}}
\citation{deng2013exploring}
\citation{deng2013exploring}
\citation{chambolle2010introduction}
\citation{avron2010L1}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Sparse regularization: skeleton extraction\cite  {huang2013l1}. Given an unorganized, unoriented, and incomplete raw scan with noise and outliers(b), a complete and quality curve skeleton is extracted(c).}}{11}{figure.11}}
\newlabel{fig:skeleton extraction}{{11}{11}{Sparse regularization: skeleton extraction\cite {huang2013l1}. Given an unorganized, unoriented, and incomplete raw scan with noise and outliers(b), a complete and quality curve skeleton is extracted(c)}{figure.11}{}}
\newlabel{eq:localmodeling1}{{38}{11}{Deformation-Constrained Modeling\relax }{equation.4.38}{}}
\newlabel{eq:localmodeling1}{{39}{11}{Deformation-Constrained Modeling\relax }{equation.4.39}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Sparse regularization: constraint modeling\cite  {deng2013exploring}. Local modifications of a constrained mesh. A glass structure composed of planar quads is locally deformed by exploring a subspace encoding local planar modifications of its central zone.}}{11}{figure.12}}
\newlabel{fig:localmodeling}{{12}{11}{Sparse regularization: constraint modeling\cite {deng2013exploring}. Local modifications of a constrained mesh. A glass structure composed of planar quads is locally deformed by exploring a subspace encoding local planar modifications of its central zone}{figure.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Total Variation(TV) Based Applications}{11}{subsection.4.6}}
\newlabel{subsec:TV Applications}{{4.6}{11}{Total Variation(TV) Based Applications\relax }{subsection.4.6}{}}
\newlabel{eq:descreteTV}{{40}{11}{Total Variation(TV) Based Applications\relax }{equation.4.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Point cloud consolidation}{11}{subsubsection.4.6.1}}
\newlabel{subsubsec:TVPoint cloud consolidation}{{4.6.1}{11}{Point cloud consolidation\relax }{subsubsection.4.6.1}{}}
\newlabel{eq:TVconsolidation1}{{41}{11}{Point cloud consolidation\relax }{equation.4.41}{}}
\citation{lipman2007parameterization}
\citation{lipman2007parameterization}
\citation{he2013mesh}
\citation{zhang2014variational}
\citation{zhang2014variational}
\citation{zhang2014variational}
\@LN@col{1}
\newlabel{eq:TVconsolidation2}{{42}{12}{Point cloud consolidation\relax }{equation.4.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Sparse regularization: TV based point cloud consolidation\cite  {lipman2007parameterization}. The Armadillo statue(left) is scanned generating a noisy point-cloud(middle). The right figure shows the consolidation result preserving the sharp features.}}{12}{figure.13}}
\newlabel{fig:TV consolidation}{{13}{12}{Sparse regularization: TV based point cloud consolidation\cite {lipman2007parameterization}. The Armadillo statue(left) is scanned generating a noisy point-cloud(middle). The right figure shows the consolidation result preserving the sharp features}{figure.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}Mesh Denoising}{12}{subsubsection.4.6.2}}
\newlabel{subsubsec:mesh denoising}{{4.6.2}{12}{Mesh Denoising\relax }{subsubsection.4.6.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Piecewise constant function spaces and operators}{12}{section*.9}}
\newlabel{eq:edgejump}{{43}{12}{Piecewise constant function spaces and operators\relax }{equation.4.43}{}}
\newlabel{eq:edgegradient}{{44}{12}{Piecewise constant function spaces and operators\relax }{equation.4.44}{}}
\@LN@col{2}
\newlabel{eq:edgedivergence}{{45}{12}{Piecewise constant function spaces and operators\relax }{equation.4.45}{}}
\newlabel{eq:elementtv}{{46}{12}{Piecewise constant function spaces and operators\relax }{equation.4.46}{}}
\newlabel{eq:vectorialspace}{{47}{12}{Piecewise constant function spaces and operators\relax }{equation.4.47}{}}
\newlabel{eq:vectorialtv}{{48}{12}{Piecewise constant function spaces and operators\relax }{equation.4.48}{}}
\@writefile{toc}{\contentsline {paragraph}{Variational model}{12}{section*.10}}
\newlabel{eq:denoisingmodeltv1}{{49}{12}{Variational model\relax }{equation.4.49}{}}
\newlabel{eq:denoisingmodeltv2}{{50}{12}{Variational model\relax }{equation.4.50}{}}
\citation{zhang2012variational}
\citation{mumford1989optimal}
\citation{zhang2012variational}
\citation{zhang2012variational}
\citation{chen2009benchmark}
\citation{zhang2012variational}
\citation{chen2009benchmark}
\citation{zhang2014local}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Sparse regularization: TV based mesh denoising\cite  {zhang2014variational}. (a): clean meshes. (b): noisy mesh(Gaussian noise, standard deviation=0.2 mean edge length for Cube; standard deviation=0.1 mean edge length for Fandisk). (c): denoising result.}}{13}{figure.14}}
\newlabel{fig:denoise_tv}{{14}{13}{Sparse regularization: TV based mesh denoising\cite {zhang2014variational}. (a): clean meshes. (b): noisy mesh(Gaussian noise, standard deviation=0.2 mean edge length for Cube; standard deviation=0.1 mean edge length for Fandisk). (c): denoising result}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.3}Decomposition}{13}{subsubsection.4.6.3}}
\newlabel{subsubsection:Decompsition}{{4.6.3}{13}{Decomposition\relax }{subsubsection.4.6.3}{}}
\newlabel{eq:TV image M-S}{{51}{13}{Decomposition\relax }{equation.4.51}{}}
\newlabel{eq:TV surface M-S}{{52}{13}{Decomposition\relax }{equation.4.52}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Sparse regularization: TV based mesh decomposition\cite  {zhang2012variational}. Decomposition results where the models are taken from the Princeton Segmentation Benchmark\cite  {chen2009benchmark}. One mesh is shown for each category. The segmentation results match results match human perception well in not only the cutting boundaries but also the number of segments.}}{13}{figure.15}}
\newlabel{fig:segmentation}{{15}{13}{Sparse regularization: TV based mesh decomposition\cite {zhang2012variational}. Decomposition results where the models are taken from the Princeton Segmentation Benchmark\cite {chen2009benchmark}. One mesh is shown for each category. The segmentation results match results match human perception well in not only the cutting boundaries but also the number of segments}{figure.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.4}Barycentric coordinates}{13}{subsubsection.4.6.4}}
\newlabel{subsubsec:Barycentric coordinates}{{4.6.4}{13}{Barycentric coordinates\relax }{subsubsection.4.6.4}{}}
\citation{zhang2014local}
\citation{zhang2014local}
\citation{aharon2006svd}
\citation{digne2014self}
\citation{le2012smooth}
\@LN@col{1}
\newlabel{eq:BC}{{53}{14}{Barycentric coordinates\relax }{equation.4.53}{}}
\newlabel{eq:continuousLBC}{{54}{14}{Barycentric coordinates\relax }{equation.4.54}{}}
\newlabel{eq:discreteLBC}{{55}{14}{Barycentric coordinates\relax }{equation.4.55}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Sparse regularization: TV based local barycentric coordinates\cite  {zhang2014local}. Using LBC for 3D cage-based manipulation allows for local, smooth and shape-aware deformations. Only parts near the manipulated control points are deformed, as indicated by the color-coding.}}{14}{figure.16}}
\newlabel{fig:LBC}{{16}{14}{Sparse regularization: TV based local barycentric coordinates\cite {zhang2014local}. Using LBC for 3D cage-based manipulation allows for local, smooth and shape-aware deformations. Only parts near the manipulated control points are deformed, as indicated by the color-coding}{figure.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Dictionary Learning}{14}{section.5}}
\newlabel{sec:DictionaryLearning}{{5}{14}{Dictionary Learning\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Deformation-Blend Skinning}{14}{subsection.5.1}}
\newlabel{subsec:LBS}{{5.1}{14}{Deformation-Blend Skinning\relax }{subsection.5.1}{}}
\citation{le2012smooth}
\citation{le2013two}
\citation{schaefer2007example}
\citation{le2014ras}
\@LN@col{1}
\newlabel{eq:LBS}{{56}{15}{Deformation-Blend Skinning\relax }{equation.5.56}{}}
\@writefile{toc}{\contentsline {paragraph}{(1)}{15}{section*.11}}
\newlabel{eq:SSDR}{{57}{15}{(1)\relax }{equation.5.57}{}}
\@writefile{toc}{\contentsline {paragraph}{(2)}{15}{section*.12}}
\@LN@col{2}
\newlabel{eq:TwoLayer}{{58}{15}{(2)\relax }{equation.5.58}{}}
\@writefile{toc}{\contentsline {paragraph}{(3)}{15}{section*.13}}
\newlabel{eq:SkeletonLBS}{{59}{15}{(3)\relax }{equation.5.59}{}}
\citation{le2014ras}
\citation{le2012smooth}
\citation{le2013two}
\citation{le2014ras}
\citation{le2012smooth}
\citation{le2013two}
\citation{le2014ras}
\citation{neumann2013sparse}
\citation{zou2006sparse}
\citation{zou2006sparse}
\citation{neumann2013sparse}
\citation{neumann2013sparse}
\citation{neumann2013sparse}
\citation{xiong2014robust}
\@LN@col{1}
\newlabel{eq:SRFE}{{60}{16}{(3)\relax }{equation.5.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Dictionary learning: skinning results. (a): \cite  {le2012smooth}, left: a set of example poses are decomposed into rigid bone transformation B and a sparse, convex bone-vertex weight map W. right: results of SSDR on elastic models. (b): \cite  {le2013two}, left: two-layer scheme. right: an animated mesh sequence and its corresponding compressed skinning model. (c): \cite  {le2014ras}, result of rigging various models such as quadrupled animals, humans, and highly deformable models.}}{16}{figure.17}}
\newlabel{fig:skinning}{{17}{16}{Dictionary learning: skinning results. (a): \cite {le2012smooth}, left: a set of example poses are decomposed into rigid bone transformation B and a sparse, convex bone-vertex weight map W. right: results of SSDR on elastic models. (b): \cite {le2013two}, left: two-layer scheme. right: an animated mesh sequence and its corresponding compressed skinning model. (c): \cite {le2014ras}, result of rigging various models such as quadrupled animals, humans, and highly deformable models}{figure.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Decomposition}{16}{subsection.5.2}}
\newlabel{subsec:decomposition}{{5.2}{16}{Decomposition\relax }{subsection.5.2}{}}
\@LN@col{2}
\newlabel{eq:edgecotanoperator}{{61}{16}{Decomposition\relax }{equation.5.61}{}}
\newlabel{eq:sparselocal}{{62}{16}{Decomposition\relax }{equation.5.62}{}}
\newlabel{eq:sparselocal}{{63}{16}{Decomposition\relax }{equation.5.63}{}}
\citation{xiong2014robust}
\citation{xiong2014robust}
\citation{digne2014self}
\citation{aharon2006svd}
\citation{digne2014self}
\citation{digne2014self}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Dictionary learning: decomposition\cite  {neumann2013sparse}. A new facial expression is generated by summing deformation components, the method automatically separates spatially confined effects like separate eyebrow motions from the data.}}{17}{figure.18}}
\newlabel{fig:localdefor}{{18}{17}{Dictionary learning: decomposition\cite {neumann2013sparse}. A new facial expression is generated by summing deformation components, the method automatically separates spatially confined effects like separate eyebrow motions from the data}{figure.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Reconstruction}{17}{subsection.5.3}}
\newlabel{subsec:reconstruction}{{5.3}{17}{Reconstruction\relax }{subsection.5.3}{}}
\newlabel{eq:dictreconstruction}{{64}{17}{Reconstruction\relax }{equation.5.64}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Dictionary learning: reconstruction\cite  {xiong2014robust}. Left: (Top)an illustration of the reconstruction problem. Given point set $\mathbb  {P}$(blue) sampled from surface \textsl  {S}, they approximate S with piecewise linear surface \textsl  {M} with vertices $\mathbb  {V}$(red) and triangles $\mathbb  {F}$. (Bottom) The reconstruction problem where $P$ is the position of sample point set. $V$ is the dictionary and $B$(green) is the sparse coding matrix that encodes triangles $\mathbb  {F}$. Right: reconstruction result of the Merlion model.}}{17}{figure.19}}
\newlabel{fig:reconstructionlearning}{{19}{17}{Dictionary learning: reconstruction\cite {xiong2014robust}. Left: (Top)an illustration of the reconstruction problem. Given point set $\mathbb {P}$(blue) sampled from surface \textsl {S}, they approximate S with piecewise linear surface \textsl {M} with vertices $\mathbb {V}$(red) and triangles $\mathbb {F}$. (Bottom) The reconstruction problem where $P$ is the position of sample point set. $V$ is the dictionary and $B$(green) is the sparse coding matrix that encodes triangles $\mathbb {F}$. Right: reconstruction result of the Merlion model}{figure.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Compression}{17}{subsection.5.4}}
\newlabel{subsec:compression}{{5.4}{17}{Compression\relax }{subsection.5.4}{}}
\@writefile{toc}{\contentsline {paragraph}{(1)}{17}{section*.14}}
\newlabel{eq:dictcompression}{{65}{17}{(1)\relax }{equation.5.65}{}}
\@writefile{toc}{\contentsline {paragraph}{(2)}{17}{section*.15}}
\citation{miandji2013learning}
\citation{miandji2013learning}
\citation{miandji2013learning}
\citation{jin2012unsupervised}
\citation{wang2014upright}
\citation{jin2012unsupervised}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Dictionary learning: point cloud compression\cite  {digne2014self}. (a): the local neighborhood description: a height map over a radial grid. (b): dictionary built for the Lovers(c) and the atoms are shown by order of importance(total absolute weight in the linear decompositions). (c): the Lovers(15.8 million points) is compressed down to 1.15 MB. The resulting model(right) is very close to the original one(left), as the reconstruction error is less than the laser scanner precision(0.02mm) for 99.14\% of the input points.}}{18}{figure.20}}
\newlabel{fig:compressionlearning}{{20}{18}{Dictionary learning: point cloud compression\cite {digne2014self}. (a): the local neighborhood description: a height map over a radial grid. (b): dictionary built for the Lovers(c) and the atoms are shown by order of importance(total absolute weight in the linear decompositions). (c): the Lovers(15.8 million points) is compressed down to 1.15 MB. The resulting model(right) is very close to the original one(left), as the reconstruction error is less than the laser scanner precision(0.02mm) for 99.14\% of the input points}{figure.20}{}}
\newlabel{eq:L1reconstruction}{{66}{18}{(2)\relax }{equation.5.66}{}}
\@LN@col{2}
\newlabel{eq:L1reconstruction}{{67}{18}{(2)\relax }{equation.5.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Sparse decomposition: rendering\cite  {miandji2013learning}. (a): the 4D SLF function $f(u,v,\phi ,\theta )$ is represented as a hemispherical radiance distribution function, HRDF. (b): rendering results using CEOB for three scenes with different materials.}}{18}{figure.21}}
\newlabel{fig:renderinglearning}{{21}{18}{Sparse decomposition: rendering\cite {miandji2013learning}. (a): the 4D SLF function $f(u,v,\phi ,\theta )$ is represented as a hemispherical radiance distribution function, HRDF. (b): rendering results using CEOB for three scenes with different materials}{figure.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Low Rank}{18}{section.6}}
\newlabel{sec:LowRank}{{6}{18}{Low Rank\relax }{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Upright orientation}{18}{subsection.6.1}}
\newlabel{subsec:upright orientation}{{6.1}{18}{Upright orientation\relax }{subsection.6.1}{}}
\citation{wang2014upright}
\citation{jin2012unsupervised}
\citation{jin2012unsupervised}
\citation{wang2014upright}
\citation{jin2012unsupervised}
\citation{wang2014upright}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Low rank: observation. (a): local method\cite  {jin2012unsupervised}. (b): global method\cite  {wang2014upright}.}}{19}{figure.22}}
\newlabel{fig:lowrank}{{22}{19}{Low rank: observation. (a): local method\cite {jin2012unsupervised}. (b): global method\cite {wang2014upright}}{figure.22}{}}
\@LN@col{1}
\@writefile{toc}{\contentsline {paragraph}{(1)}{19}{section*.16}}
\newlabel{eq:UprightJin}{{68}{19}{(1)\relax }{equation.6.68}{}}
\@writefile{toc}{\contentsline {paragraph}{(2)}{19}{section*.17}}
\@LN@col{2}
\newlabel{eq:UprightJin}{{69}{19}{(2)\relax }{equation.6.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Low rank: unsupervised upright orientation. (a): local method\cite  {jin2012unsupervised}. (b): global method\cite  {wang2014upright}.}}{19}{figure.23}}
\newlabel{fig:upright_lowrank}{{23}{19}{Low rank: unsupervised upright orientation. (a): local method\cite {jin2012unsupervised}. (b): global method\cite {wang2014upright}}{figure.23}{}}
\citation{zhang2013point}
\citation{zhang2013point}
\citation{zhang2013point}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Point cloud normal estimation}{20}{subsection.6.2}}
\newlabel{subsec:normal estimation}{{6.2}{20}{Point cloud normal estimation\relax }{subsection.6.2}{}}
\newlabel{eq:LSC}{{70}{20}{Point cloud normal estimation\relax }{equation.6.70}{}}
\newlabel{eq:LRSCPK}{{71}{20}{Point cloud normal estimation\relax }{equation.6.71}{}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Low rank: normal estimation\cite  {zhang2013point}. (a): the oil pump module with normal computed by PCA. (b): initial detected candidate feature points. (c): the classified subneighborhoods. The neighborhood within the red box contains three subneighborhoods rendered in blue, green and brown and the zoomed view is from left. (d): estimated normals.}}{20}{figure.24}}
\newlabel{fig:normal_lowrank}{{24}{20}{Low rank: normal estimation\cite {zhang2013point}. (a): the oil pump module with normal computed by PCA. (b): initial detected candidate feature points. (c): the classified subneighborhoods. The neighborhood within the red box contains three subneighborhoods rendered in blue, green and brown and the zoomed view is from left. (d): estimated normals}{figure.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of applications between image and geometry.}}{20}{table.3}}
\newlabel{table:applications}{{3}{20}{Comparison of applications between image and geometry}{table.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{20}{section.7}}
\newlabel{sec:Discussion}{{7}{20}{Discussion\relax }{section.7}{}}
\@writefile{toc}{\contentsline {paragraph}{(1)}{20}{section*.18}}
\@writefile{toc}{\contentsline {paragraph}{(2)}{20}{section*.19}}
\bibdata{sparsesurvey}
\bibcite{mallat1993matching}{{1}{}{{}}{{}}}
\bibcite{pati1993orthogonal}{{2}{}{{}}{{}}}
\bibcite{tropp2007signal}{{3}{}{{}}{{}}}
\bibcite{tibshirani1996regression}{{4}{}{{}}{{}}}
\bibcite{efron2004least}{{5}{}{{}}{{}}}
\bibcite{wright2010sparse}{{6}{}{{}}{{}}}
\bibcite{wright2009robust}{{7}{}{{}}{{}}}
\bibcite{yang2008image}{{8}{}{{}}{{}}}
\bibcite{mairal2008discriminative}{{9}{}{{}}{{}}}
\bibcite{olshausen1997sparse}{{10}{}{{}}{{}}}
\bibcite{engan1999frame}{{11}{}{{}}{{}}}
\bibcite{aharon2006svd}{{12}{}{{}}{{}}}
\bibcite{jolliffe2005principal}{{13}{}{{}}{{}}}
\bibcite{wold1987principal}{{14}{}{{}}{{}}}
\bibcite{candes2011robust}{{15}{}{{}}{{}}}
\bibcite{candes2009exact}{{16}{}{{}}{{}}}
\bibcite{lin2010augmented}{{17}{}{{}}{{}}}
\bibcite{grant2008cvx}{{18}{}{{}}{{}}}
\bibcite{beck2009fast}{{19}{}{{}}{{}}}
\bibcite{lin2009fast}{{20}{}{{}}{{}}}
\bibcite{bertsekas1982constrained}{{21}{}{{}}{{}}}
\bibcite{bertsekas1999nonlinear}{{22}{}{{}}{{}}}
\bibcite{ma2012sparse}{{23}{}{{}}{{}}}
\bibcite{shen2012unified}{{24}{}{{}}{{}}}
\bibcite{ji2010robust}{{25}{}{{}}{{}}}
\bibcite{lipman2007parameterization}{{26}{}{{}}{{}}}
\bibcite{huang2009consolidation}{{27}{}{{}}{{}}}
\bibcite{preiner2014CPF}{{28}{}{{}}{{}}}
\bibcite{avron2010L1}{{29}{}{{}}{{}}}
\bibcite{mustafa2014subdivision}{{30}{}{{}}{{}}}
\bibcite{zhang2013point}{{31}{}{{}}{{}}}
\bibcite{he2013mesh}{{32}{}{{}}{{}}}
\bibcite{wang2014decoupling}{{33}{}{{}}{{}}}
\bibcite{zhang2014variational}{{34}{}{{}}{{}}}
\bibcite{bouaziz2013sparse}{{35}{}{{}}{{}}}
\@LN@col{1}
\@LN@col{2}
\bibcite{hu2012co}{{36}{}{{}}{{}}}
\bibcite{digne2014self}{{37}{}{{}}{{}}}
\bibcite{miandji2013learning}{{38}{}{{}}{{}}}
\bibcite{zhang2012variational}{{39}{}{{}}{{}}}
\bibcite{neumann2013sparse}{{40}{}{{}}{{}}}
\bibcite{le2012smooth}{{41}{}{{}}{{}}}
\bibcite{le2013two}{{42}{}{{}}{{}}}
\bibcite{le2014ras}{{43}{}{{}}{{}}}
\bibcite{deng2013exploring}{{44}{}{{}}{{}}}
\bibcite{jin2012unsupervised}{{45}{}{{}}{{}}}
\bibcite{wang2014upright}{{46}{}{{}}{{}}}
\bibcite{neumann2014compressed}{{47}{}{{}}{{}}}
\bibcite{zhang2014local}{{48}{}{{}}{{}}}
\bibcite{huang2013l1}{{49}{}{{}}{{}}}
\bibcite{xiong2014robust}{{50}{}{{}}{{}}}
\bibcite{brown1983statistical}{{51}{}{{}}{{}}}
\bibcite{small1990survey}{{52}{}{{}}{{}}}
\bibcite{xu2011image}{{53}{}{{}}{{}}}
\bibcite{pinkall1993computing}{{54}{}{{}}{{}}}
\bibcite{chartrand2007exact}{{55}{}{{}}{{}}}
\bibcite{elad2010sparse}{{56}{}{{}}{{}}}
\bibcite{ovsjanikov2012functional}{{57}{}{{}}{{}}}
\bibcite{pokrass2013sparse}{{58}{}{{}}{{}}}
\bibcite{litman2011diffusion}{{59}{}{{}}{{}}}
\bibcite{elhamifar2009sparse}{{60}{}{{}}{{}}}
\bibcite{wang2011efficient}{{61}{}{{}}{{}}}
\bibcite{shi2000normalized}{{62}{}{{}}{{}}}
\bibcite{cornea2007curve}{{63}{}{{}}{{}}}
\bibcite{chambolle2010introduction}{{64}{}{{}}{{}}}
\bibcite{mumford1989optimal}{{65}{}{{}}{{}}}
\bibcite{chen2009benchmark}{{66}{}{{}}{{}}}
\bibcite{schaefer2007example}{{67}{}{{}}{{}}}
\bibcite{zou2006sparse}{{68}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@LN@col{1}
\@LN@col{2}
