\section{Introduction}
\label{sec:Introduction}
Because of the fast development of Internet and other electronic equipments, the size of dataset is becoming  incredibly massive.
How to extract compact knowledge from such massive datasets is yet to be resolved.
At the same time, the dimension of data becomes much higher than before.
Thus how to extract low-dimensional structures from high-dimensional data is another serious problem in modern signal processing.

To solve these two challenging problems, sparsity-based approaches have been successfully introduced in many applications.
Sparse representation which models data vectors as sparse linear combinations of basis elements, is widely used in machine learning, signal processing, neuroscience and statistics.
Dictionary learning learns an overcomplete dictionary which owns the ability to represent given signals.
Low rank representation which decomposes a given matrix into a low rank matrix and residual with certain property.
So far sparse techniques have become state-of-art tools in many fields like machine learning, data mining, computer vision, pattern recognition etc.
%Sparse representation of signals has been drawing much attention of the researchers.

In geometric processing and computer graphics, people start to find out the advantages of sparse techniques.
More and more papers formulate problems in the sense of sparsity. 